{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"center\" src=\"http://sydney.edu.au/images/content/about/logo-mono.jpg\">\n",
    "<h1 align=\"center\" style=\"margin-top:10px\">Advanced Analytics (QBUS3830)</h1>\n",
    "<h2 align=\"center\" style=\"margin-top:10px\">Homework Task 1</h2>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Logistic Regression\n",
    "\n",
    "\n",
    "### Bernoulli distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bernoulli_log_like(pi, y):\n",
    "    loglik = y*np.log(pi)+(1-y)*np.log(1-pi)\n",
    "    return np.sum(loglik)\n",
    "\n",
    "def bernoulli_score(pi, y):\n",
    "    return  y/pi-(1-y)/(1-pi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Link function, inverse link function, and derivative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import logit, expit\n",
    "\n",
    "def expit_derivative(x):\n",
    "    y = expit(x)\n",
    "    return y*(1-y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss function for minimisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bernoulli_loss(pi, y):\n",
    "    n = len(y)\n",
    "    return -(bernoulli_log_like(pi, y)/n)\n",
    "\n",
    "def bernoulli_logit_loss(nu, y):\n",
    "    pi = expit(nu)\n",
    "    return bernoulli_loss(pi, y)\n",
    "\n",
    "def logistic_reg_loss(pi,y):\n",
    "    return (-y * np.log(pi) - (1 - y) * np.log(1 - pi)).mean()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient of the loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_reg_loss_jac(pi, y): # complete the function head   \n",
    "    n = len(y)\n",
    "    # something goes here\n",
    "    return (-y * np.log(pi) - (1 - y) * np.log(1 - pi)).mean()\n",
    "    pi = expit(nu)\n",
    "    jac = -bernoulli_score(pi, y)/n\n",
    "    jac = jac*expit_derivative(nu)\n",
    "    # keep working here, you must use the chain rule\n",
    "    # pay attention to the required output\n",
    "    return logistic_reg_loss_jac(pi, y)*expit_derivative(nu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression:\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X_train, y_train):  \n",
    "               \n",
    "        n = len(y_train)\n",
    "        \n",
    "        # there is code that goes here\n",
    "        \n",
    "        output= minimize(logistic_reg_loss, start, args=(X_train, y_train), jac = logistic_reg_jac, tol=1e-6, method='L-BFGS-B') \n",
    "        \n",
    "        self.output = output\n",
    "        \n",
    "        self.coef = output.x # logistic regression coefficients\n",
    "        \n",
    "        self.se=np.sqrt(np.diag((1/n)*output.hess_inv.todense()))\n",
    "        \n",
    "    def predict(self, X): \n",
    "        # predicts one or zero given the predictor values, complete the function\n",
    "        # predict one if the conditionnal probability is higher than 0.5\n",
    "        pass\n",
    "    \n",
    "    def predict_proba(self, X): \n",
    "        # computes the conditional probability given the predictor values, complete the function\n",
    "        pass\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Test code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Data and benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Acquisition</th>\n",
       "      <th>Acq_Expense</th>\n",
       "      <th>Industry</th>\n",
       "      <th>Revenue</th>\n",
       "      <th>Employees</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Customer</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>760.36</td>\n",
       "      <td>1</td>\n",
       "      <td>30.16</td>\n",
       "      <td>1240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>147.70</td>\n",
       "      <td>1</td>\n",
       "      <td>39.80</td>\n",
       "      <td>166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>252.56</td>\n",
       "      <td>1</td>\n",
       "      <td>54.93</td>\n",
       "      <td>1016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>609.73</td>\n",
       "      <td>1</td>\n",
       "      <td>45.83</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>672.36</td>\n",
       "      <td>1</td>\n",
       "      <td>69.03</td>\n",
       "      <td>313</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Acquisition  Acq_Expense  Industry  Revenue  Employees\n",
       "Customer                                                        \n",
       "1                   1       760.36         1    30.16       1240\n",
       "2                   0       147.70         1    39.80        166\n",
       "3                   0       252.56         1    54.93       1016\n",
       "4                   1       609.73         1    45.83        122\n",
       "5                   1       672.36         1    69.03        313"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('Data\\Acquisition.csv', index_col=0)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "y_train= data['Acquisition']\n",
    "X_train= sm.add_constant(data.iloc[:,1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.217643\n",
      "         Iterations 9\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:            Acquisition   No. Observations:                  500\n",
      "Model:                          Logit   Df Residuals:                      495\n",
      "Method:                           MLE   Df Model:                            4\n",
      "Date:                Tue, 28 Aug 2018   Pseudo R-squ.:                  0.6795\n",
      "Time:                        13:20:39   Log-Likelihood:                -108.82\n",
      "converged:                       True   LL-Null:                       -339.48\n",
      "                                        LLR p-value:                 1.546e-98\n",
      "===============================================================================\n",
      "                  coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------\n",
      "const         -13.5205      1.497     -9.033      0.000     -16.454     -10.587\n",
      "Acq_Expense     0.0215      0.002      9.678      0.000       0.017       0.026\n",
      "Industry        0.1127      0.364      0.310      0.757      -0.601       0.826\n",
      "Revenue         0.0274      0.011      2.471      0.013       0.006       0.049\n",
      "Employees       0.0038      0.001      6.961      0.000       0.003       0.005\n",
      "===============================================================================\n"
     ]
    }
   ],
   "source": [
    "sm_logit = sm.Logit(y_train, X_train).fit()\n",
    "print(sm_logit.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Testing your implementation\n",
    "\n",
    "It's time to test your code. Do you get the same coefficients and standard errors as the package, or least very similar?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit = LogisticRegression()\n",
    "logit.fit(X_train, y_train) # following the Scikit-Learn syntax\n",
    "\n",
    "print(logit.coef)\n",
    "print(logit.se)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Robit model\n",
    "\n",
    "The Robit model is identical to the logistic regression model, except that the link function is the inverse of the Student's t CDF with fixed degrees of freedom. Adapt the code from above to estimate it, but you will have to go back to the code from the lecturer to find the optimisation approach that will work for this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Robit:\n",
    "    \n",
    "    def __init__(self, nu=5):\n",
    "        self.nu = nu # degrees of freedom \n",
    "    \n",
    "    def fit(self, X_train, y_train):  \n",
    "               \n",
    "        n = len(y_train)\n",
    "        \n",
    "        # complete the function\n",
    "\n",
    "        self.se=np.sqrt(np.diag((1/n)*output.hess_inv.todense()))\n",
    "        \n",
    "    def predict(self, X): \n",
    "        # predicts one or zero given the predictor values, complete the function\n",
    "        # predict one if the conditionnal probability is higher than 0.5\n",
    "        pass\n",
    "    \n",
    "    def predict_proba(self, X): \n",
    "        # computes the conditional probability given the predictor values, complete the function\n",
    "        pass\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Predictive analytics\n",
    "\n",
    "### 4.1 Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "response='Acquisition'\n",
    "predictors = list(data.columns.values)\n",
    "predictors.remove(response)\n",
    "\n",
    "data['Acq_Expense'] = np.log(data['Acq_Expense'])\n",
    "\n",
    "\n",
    "index_train, index_test  = train_test_split(np.array(data.index), stratify=data[response], train_size=0.7, random_state=5)\n",
    "\n",
    "y_train = data[response].copy()\n",
    "y_test = data[response].copy()\n",
    "\n",
    "X_train = data.loc[index_train, predictors].copy()\n",
    "X_test =  data.loc[index_test, predictors].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Maximum Likelihood Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit = LogisticRegression()\n",
    "logit.fit(X_train, y_train)\n",
    "\n",
    "robit = Robit(nu=5) # you can experiment with different degrees of freedom\n",
    "robit.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, roc_auc_score, precision_score\n",
    "\n",
    "columns=['Accuracy', 'Sensitivity', 'Specificity', 'AUC', 'Precision']\n",
    "rows=['Logistic regression', 'Robit']\n",
    "results=pd.DataFrame(0.0, columns=columns, index=rows) \n",
    "\n",
    "methods=[logit, robit]\n",
    "\n",
    "for i, method in enumerate(methods):\n",
    "    \n",
    "    y_pred = method.predict(X_test)\n",
    "    y_prod = method.predict_proba(X_test)\n",
    "\n",
    "    confusion  = confusion_matrix(y_test, y_pred)\n",
    "    results.iloc[i,0]=  accuracy_score(y_test, y_pred)\n",
    "    results.iloc[i,1]=  confusion[1,1]/np.sum(confusion[1,:])\n",
    "    results.iloc[i,2]=  confusion[0,0]/np.sum(confusion[0,:])\n",
    "    results.iloc[i,4]=  precision_score(y_test, y_pred)\n",
    "\n",
    "    results.iloc[i,3] = roc_auc_score(y_test, y_prob)\n",
    "\n",
    "results.round(3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
